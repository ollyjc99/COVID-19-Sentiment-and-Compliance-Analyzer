{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "protecting-passing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Separate notebook to work on Topic Modelling with LDA\n",
    "%pylab inline\n",
    "from sys import platform\n",
    "import pandas as pd\n",
    "\n",
    "if platform == \"win32\":\n",
    "    path = 'C:/Users/olive/'\n",
    "elif platform == \"darwin\":\n",
    "    path = '~/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enormous-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.read_pickle(path + 'OneDrive - Cardiff University/Individual Project/processed data/comments.csv')\n",
    "s_df = pd.read_pickle(path + 'OneDrive - Cardiff University/Individual Project/processed data/submissions.csv')\n",
    "\n",
    "s_df = s_df.sort_values(by='datetime')\n",
    "c_df = c_df.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affected-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>538420</th>\n",
       "      <td>Exactly. I don't mean to be mean but I don't u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289030</th>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235804</th>\n",
       "      <td>I am not supporting or defending or suggesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315874</th>\n",
       "      <td>Finally someone who speaks my language. That's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378895</th>\n",
       "      <td>They can leave it on your doorstep stand back ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     body\n",
       "538420  Exactly. I don't mean to be mean but I don't u...\n",
       "289030                                          [deleted]\n",
       "235804  I am not supporting or defending or suggesting...\n",
       "315874  Finally someone who speaks my language. That's...\n",
       "378895  They can leave it on your doorstep stand back ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = c_df.reset_index().drop(columns=['id', 'datetime', 'sentiment', 'compound_score', 'submission_id', 'parent_id'], axis=1)\n",
    "\n",
    "comments = comments.sample(100)\n",
    "\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "particular-bachelor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538420    exactly i don't mean to be mean but i don't un...\n",
       "289030                                            [deleted]\n",
       "235804    i am not supporting or defending or suggesting...\n",
       "315874    finally someone who speaks my language that's ...\n",
       "378895    they can leave it on your doorstep stand back ...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "import re\n",
    "\n",
    "comments['processed_text'] = comments['body'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "comments['processed_text'] = comments['processed_text'].map(lambda x: x.lower())\n",
    "\n",
    "comments['processed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "actual-nickel",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9607453f58ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# EXPLORATORY ANALYSIS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlong_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "# EXPLORATORY ANALYSIS\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "long_string = ','.join(list(comments['processed_text'].values))\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words=5000,\n",
    "                      contour_width=3,\n",
    "                      contour_coliur='steelblue'\n",
    "                     )\n",
    "\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "wordcloud.to_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interracial-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exactly', 'don', 'mean', 'to', 'be', 'mean', 'but', 'don', 'understand', 'these', 'people', 'who', 'have', 'stayed', 'in', 'for', 'nearly', 'year', 'surely', 'at', 'some', 'point', 'you', 'could', 'have', 'made', 'the', 'trip', 'to', 'see']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize words and more text clean-up\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence),\n",
    "                                            deacc=True))\n",
    "data = comments.processed_text.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fancy-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bigram and Trigram Phrase Modelling\n",
    "\n",
    "bigram = gensim.models.Phrases(\n",
    "    data_words, min_count=5, threshold=100\n",
    ")\n",
    "trigram = gensim.models.Phrases(\n",
    "    bigram[data_words], threshold=100\n",
    ")\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latter-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords, Make Bigrams and Lemmantize\n",
    "\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stuck-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "composite-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['exactly', 'mean', 'mean', 'understand', 'people', 'stay', 'nearly', 'year', 'surely', 'point', 'make', 'trip', 'see', 'want']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser',\n",
    "                                            'ner'])\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, \n",
    "                                allowed_postags=['NOUN', \n",
    "                                                 'ADJ', \n",
    "                                                 'VERB', \n",
    "                                                 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "advisory-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]]\n"
     ]
    }
   ],
   "source": [
    "#Data Tranformation: Corpus and Dictionary\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interstate-andorra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.015*\"say\" + 0.015*\"week\" + 0.014*\"take\" + 0.014*\"delete\" + 0.014*\"show\" + '\n",
      "  '0.008*\"people\" + 0.007*\"year\" + 0.007*\"work\" + 0.007*\"job\" + '\n",
      "  '0.007*\"measure\"'),\n",
      " (1,\n",
      "  '0.025*\"people\" + 0.011*\"travel\" + 0.011*\"double\" + 0.007*\"unnecessary\" + '\n",
      "  '0.007*\"symptom\" + 0.007*\"get\" + 0.007*\"covid\" + 0.007*\"talk\" + '\n",
      "  '0.007*\"quarantine\" + 0.007*\"even\"'),\n",
      " (2,\n",
      "  '0.016*\"people\" + 0.011*\"government\" + 0.011*\"september\" + 0.011*\"back\" + '\n",
      "  '0.011*\"pad\" + 0.006*\"seem\" + 0.006*\"make\" + 0.006*\"try\" + 0.006*\"early\" + '\n",
      "  '0.006*\"good\"'),\n",
      " (3,\n",
      "  '0.016*\"https\" + 0.010*\"people\" + 0.010*\"well\" + 0.010*\"say\" + 0.010*\"thing\" '\n",
      "  '+ 0.010*\"test\" + 0.006*\"go\" + 0.006*\"get\" + 0.006*\"work\" + 0.006*\"much\"'),\n",
      " (4,\n",
      "  '0.018*\"want\" + 0.018*\"mean\" + 0.014*\"day\" + 0.009*\"people\" + 0.009*\"agree\" '\n",
      "  '+ 0.009*\"need\" + 0.009*\"see\" + 0.009*\"health\" + 0.009*\"mind\" + '\n",
      "  '0.009*\"plan\"'),\n",
      " (5,\n",
      "  '0.010*\"risk\" + 0.010*\"trial\" + 0.008*\"want\" + 0.008*\"people\" + 0.008*\"go\" + '\n",
      "  '0.008*\"sneeze\" + 0.008*\"time\" + 0.008*\"thing\" + 0.008*\"take\" + '\n",
      "  '0.008*\"many\"'),\n",
      " (6,\n",
      "  '0.017*\"people\" + 0.013*\"virus\" + 0.009*\"go\" + 0.009*\"look\" + 0.009*\"total\" '\n",
      "  '+ 0.009*\"death\" + 0.009*\"back\" + 0.009*\"realise\" + 0.009*\"rich\" + '\n",
      "  '0.005*\"know\"'),\n",
      " (7,\n",
      "  '0.011*\"number\" + 0.011*\"way\" + 0.009*\"government\" + 0.009*\"world\" + '\n",
      "  '0.009*\"well\" + 0.007*\"people\" + 0.007*\"make\" + 0.007*\"system\" + '\n",
      "  '0.007*\"similar\" + 0.007*\"good\"'),\n",
      " (8,\n",
      "  '0.021*\"people\" + 0.014*\"want\" + 0.014*\"mask\" + 0.014*\"test\" + '\n",
      "  '0.011*\"general\" + 0.011*\"infection\" + 0.007*\"give\" + 0.007*\"response\" + '\n",
      "  '0.007*\"think\" + 0.007*\"thing\"'),\n",
      " (9,\n",
      "  '0.021*\"people\" + 0.018*\"test\" + 0.018*\"go\" + 0.015*\"get\" + 0.010*\"try\" + '\n",
      "  '0.009*\"swab\" + 0.009*\"covid\" + 0.009*\"know\" + 0.009*\"virus\" + '\n",
      "  '0.008*\"death\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "committed-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.37493778404559935\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "built-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning\n",
    "\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    print(corpus)\n",
    "    print(dictionary)\n",
    "    print(k)\n",
    "    print(a)\n",
    "    print(b)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=data_lemmatized, \n",
    "                                         dictionary=id2word,\n",
    "                                         coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "executive-species",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/540 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/COVID-19-Sentiment-and-Compliance-Analyzer/.venv/lib/python3.9/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mlencorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-769429cceaec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;31m# get the coherence score for the given parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     cv = compute_coherence_values(corpus=corpus_sets[i], \n\u001b[0m\u001b[1;32m     51\u001b[0m                                                   \u001b[0mdictionary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                                   \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-d900f66208f3>\u001b[0m in \u001b[0;36mcompute_coherence_values\u001b[0;34m(corpus, dictionary, k, a, b)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_coherence_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     lda_model = gensim.models.LdaMulticore(corpus=corpus,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                            \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                            \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/COVID-19-Sentiment-and-Compliance-Analyzer/.venv/lib/python3.9/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto-tuning alpha not implemented in multicore LDA; use plain LdaModel.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         super(LdaMulticore, self).__init__(\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/COVID-19-Sentiment-and-Compliance-Analyzer/.venv/lib/python3.9/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m             self.add_lifecycle_event(\n\u001b[1;32m    525\u001b[0m                 \u001b[0;34m\"created\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/COVID-19-Sentiment-and-Compliance-Analyzer/.venv/lib/python3.9/site-packages/gensim/models/ldamulticore.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input corpus stream has no len(); counting documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0mlencorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlencorpus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LdaMulticore.update() called with an empty corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/COVID-19-Sentiment-and-Compliance-Analyzer/.venv/lib/python3.9/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Stop argument for islice() must be None or an integer: 0 <= x <= sys.maxsize."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, num_of_docs*0.75), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "#Can take a while to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], \n",
    "                                                  dictionary=id2word, \n",
    "                                                  k=k, \n",
    "                                                  a=a,\n",
    "                                                  b=b)\n",
    "                    print('Alert')\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "                    \n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv',\n",
    "                                       index=False)\n",
    "    pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "serial-custody",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(corpus_sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-adams",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
